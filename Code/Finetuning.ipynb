{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab1e036a",
   "metadata": {},
   "source": [
    "# This notebook experiments with finetuning deep neural networks\n",
    "\n",
    "The following will be experimented:\n",
    "\n",
    "- Number of neurons and Dense Layers\n",
    "- Regularisation \n",
    "- Differnt Activation Functions\n",
    "- Learning Rates and optimisers\n",
    "- Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a21a7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 14:53:31.232485: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import all necessary packages\n",
    "\n",
    "import ast\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, hamming_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeea349",
   "metadata": {},
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4757cdb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Classification Codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>processor compil system receiv predict model r...</td>\n",
       "      <td>[G06N20/00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>system method secur cloudbas physiolog data pr...</td>\n",
       "      <td>[A61B5/00, G16H10/60]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>collim detector base medic imag system medic i...</td>\n",
       "      <td>[A61B6/00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>insul pedicl access system relat method pedicl...</td>\n",
       "      <td>[A61B5/00, A61B17/00]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ingest event marker data framework ingest even...</td>\n",
       "      <td>[A61B5/00, G16H10/60]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Context   Classification Codes\n",
       "0  processor compil system receiv predict model r...            [G06N20/00]\n",
       "1  system method secur cloudbas physiolog data pr...  [A61B5/00, G16H10/60]\n",
       "2  collim detector base medic imag system medic i...             [A61B6/00]\n",
       "3  insul pedicl access system relat method pedicl...  [A61B5/00, A61B17/00]\n",
       "4  ingest event marker data framework ingest even...  [A61B5/00, G16H10/60]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('Data_Preprocessed_SubGroup_Selected7.csv')\n",
    "df['Classification Codes'] = df['Classification Codes'].apply(ast.literal_eval)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ff08891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As most multi-label classifiers requres each class to have multiple instances.\n",
    "# All codes which appear less than 5 times will be removed\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    # Determine the codes to be removed\n",
    "    unique_codes = df['Classification Codes'].explode().value_counts()\n",
    "    codes_to_remove = unique_codes[unique_codes < 5 ].index.tolist()\n",
    "\n",
    "    # Remove rows with empty 'Classification Codes' column\n",
    "    df = df.dropna(subset=['Classification Codes'])\n",
    "\n",
    "    # Remove codes in the list codes_to_remove\n",
    "    df['CodeCount'] = df['Classification Codes'].apply(lambda codes: sum(code in codes_to_remove for code in codes))\n",
    "    df = df[df['CodeCount'] == 0].drop(columns=['CodeCount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "360b9f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode \"Classification Codes\" column as multi-labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(df['Classification Codes'])\n",
    "\n",
    "# Split the data into training(80%) and testing sets(20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Context'], y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5ef7eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature extraction using TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c955270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sparse matrices to dense NumPy arrays\n",
    "X_train_dense = X_train_vectorized.toarray()\n",
    "X_test_dense = X_test_vectorized.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c425fa",
   "metadata": {},
   "source": [
    "# Addition of more Neurons and Dense Layers\n",
    "\n",
    "The base model utilised, 2 layers with 64 and 32 neurons which achieved 0.3224\n",
    "\n",
    "I will experiment with adding more neruons or layers to attempt to increase the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef42d3f4",
   "metadata": {},
   "source": [
    "## Increase the neruon size to 128 and 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "391391ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-27 14:53:39.979346: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "122/122 [==============================] - 3s 18ms/step - loss: 0.2772 - accuracy: 0.6731 - val_loss: 0.2322 - val_accuracy: 0.7147\n",
      "Epoch 2/10\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 0.1022 - accuracy: 0.8745 - val_loss: 0.2456 - val_accuracy: 0.7127\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 0.0412 - accuracy: 0.9261 - val_loss: 0.2887 - val_accuracy: 0.7085\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 0.0162 - accuracy: 0.9379 - val_loss: 0.3428 - val_accuracy: 0.7178\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - 2s 17ms/step - loss: 0.0082 - accuracy: 0.9307 - val_loss: 0.3821 - val_accuracy: 0.7116\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.0037 - accuracy: 0.9400 - val_loss: 0.4323 - val_accuracy: 0.7116\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.0023 - accuracy: 0.9371 - val_loss: 0.4512 - val_accuracy: 0.7106\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 0.0034 - accuracy: 0.9351 - val_loss: 0.4804 - val_accuracy: 0.7137\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 0.0013 - accuracy: 0.9330 - val_loss: 0.4965 - val_accuracy: 0.7096\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 6.0096e-04 - accuracy: 0.9302 - val_loss: 0.5164 - val_accuracy: 0.7158\n",
      "38/38 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train_dense.shape[1],)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(y.shape[1], activation='sigmoid'))  # Use sigmoid activation for multi-label classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_dense, y_train, batch_size=32, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_proba = model.predict(X_test_dense)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "hamming_loss_value = hamming_loss(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5bb4e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Accuracy: 0.6731, Validation Accuracy: 0.7147\n",
      "Epoch 2 - Accuracy: 0.8745, Validation Accuracy: 0.7127\n",
      "Epoch 3 - Accuracy: 0.9261, Validation Accuracy: 0.7085\n",
      "Epoch 4 - Accuracy: 0.9379, Validation Accuracy: 0.7178\n",
      "Epoch 5 - Accuracy: 0.9307, Validation Accuracy: 0.7116\n",
      "Epoch 6 - Accuracy: 0.9400, Validation Accuracy: 0.7116\n",
      "Epoch 7 - Accuracy: 0.9371, Validation Accuracy: 0.7106\n",
      "Epoch 8 - Accuracy: 0.9351, Validation Accuracy: 0.7137\n",
      "Epoch 9 - Accuracy: 0.9330, Validation Accuracy: 0.7096\n",
      "Epoch 10 - Accuracy: 0.9302, Validation Accuracy: 0.7158\n",
      "\n",
      "Hamming Loss: 0.09331607437044011\n"
     ]
    }
   ],
   "source": [
    "# Get accuracy and validation accuracy\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Print the accuracy and validation accuracy for each epoch\n",
    "for epoch in range(len(accuracy)):\n",
    "    print(f\"Epoch {epoch + 1} - Accuracy: {accuracy[epoch]:.4f}, Validation Accuracy: {val_accuracy[epoch]:.4f}\")\n",
    "    \n",
    "# Print hamming loss\n",
    "print(\"\\nHamming Loss:\", hamming_loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80c4dbe",
   "metadata": {},
   "source": [
    "## Increase the neruon size to 256 and 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3f39430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "122/122 [==============================] - 3s 25ms/step - loss: 0.2618 - accuracy: 0.6790 - val_loss: 0.2327 - val_accuracy: 0.7116\n",
      "Epoch 2/10\n",
      "122/122 [==============================] - 4s 30ms/step - loss: 0.0872 - accuracy: 0.8818 - val_loss: 0.2528 - val_accuracy: 0.7219\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - 3s 28ms/step - loss: 0.0305 - accuracy: 0.9271 - val_loss: 0.3191 - val_accuracy: 0.7209\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - 3s 25ms/step - loss: 0.0152 - accuracy: 0.9325 - val_loss: 0.3840 - val_accuracy: 0.7343\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - 3s 24ms/step - loss: 0.0078 - accuracy: 0.9348 - val_loss: 0.4230 - val_accuracy: 0.7106\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - 3s 25ms/step - loss: 0.0029 - accuracy: 0.9402 - val_loss: 0.4444 - val_accuracy: 0.7240\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - 4s 32ms/step - loss: 0.0013 - accuracy: 0.9351 - val_loss: 0.4825 - val_accuracy: 0.7127\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - 3s 26ms/step - loss: 6.3505e-04 - accuracy: 0.9420 - val_loss: 0.5127 - val_accuracy: 0.7127\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - 3s 23ms/step - loss: 3.7768e-04 - accuracy: 0.9420 - val_loss: 0.5308 - val_accuracy: 0.7209\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - 3s 23ms/step - loss: 2.2974e-04 - accuracy: 0.9433 - val_loss: 0.5530 - val_accuracy: 0.7209\n",
      "38/38 [==============================] - 0s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_shape=(X_train_dense.shape[1],)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(y.shape[1], activation='sigmoid'))  # Use sigmoid activation for multi-label classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_dense, y_train, batch_size=32, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_proba = model.predict(X_test_dense)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "hamming_loss_value = hamming_loss(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ce71a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Accuracy: 0.6790, Validation Accuracy: 0.7116\n",
      "Epoch 2 - Accuracy: 0.8818, Validation Accuracy: 0.7219\n",
      "Epoch 3 - Accuracy: 0.9271, Validation Accuracy: 0.7209\n",
      "Epoch 4 - Accuracy: 0.9325, Validation Accuracy: 0.7343\n",
      "Epoch 5 - Accuracy: 0.9348, Validation Accuracy: 0.7106\n",
      "Epoch 6 - Accuracy: 0.9402, Validation Accuracy: 0.7240\n",
      "Epoch 7 - Accuracy: 0.9351, Validation Accuracy: 0.7127\n",
      "Epoch 8 - Accuracy: 0.9420, Validation Accuracy: 0.7127\n",
      "Epoch 9 - Accuracy: 0.9420, Validation Accuracy: 0.7209\n",
      "Epoch 10 - Accuracy: 0.9433, Validation Accuracy: 0.7209\n",
      "\n",
      "Hamming Loss: 0.09261002588844434\n"
     ]
    }
   ],
   "source": [
    "# Get accuracy and validation accuracy\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Print the accuracy and validation accuracy for each epoch\n",
    "for epoch in range(len(accuracy)):\n",
    "    print(f\"Epoch {epoch + 1} - Accuracy: {accuracy[epoch]:.4f}, Validation Accuracy: {val_accuracy[epoch]:.4f}\")\n",
    "    \n",
    "# Print hamming loss\n",
    "print(\"\\nHamming Loss:\", hamming_loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97747fa",
   "metadata": {},
   "source": [
    "## Addition of another dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f3f13e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.2894 - accuracy: 0.6512 - val_loss: 0.2517 - val_accuracy: 0.7096\n",
      "Epoch 2/10\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 0.1127 - accuracy: 0.8619 - val_loss: 0.2536 - val_accuracy: 0.7147\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 0.0474 - accuracy: 0.9150 - val_loss: 0.3085 - val_accuracy: 0.7209\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 0.0217 - accuracy: 0.9271 - val_loss: 0.3655 - val_accuracy: 0.7209\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 0.0114 - accuracy: 0.9338 - val_loss: 0.4097 - val_accuracy: 0.7044\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 0.0082 - accuracy: 0.9284 - val_loss: 0.4645 - val_accuracy: 0.7044\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 0.0062 - accuracy: 0.9317 - val_loss: 0.4874 - val_accuracy: 0.6993\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 0.0040 - accuracy: 0.9279 - val_loss: 0.5137 - val_accuracy: 0.7085\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 0.0062 - accuracy: 0.9258 - val_loss: 0.5471 - val_accuracy: 0.7055\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 0.0172 - accuracy: 0.9238 - val_loss: 0.5516 - val_accuracy: 0.6982\n",
      "38/38 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train_dense.shape[1],)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(y.shape[1], activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_dense, y_train, batch_size=32, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_proba = model.predict(X_test_dense)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "hamming_loss_value = hamming_loss(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3daa96bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Accuracy: 0.6512, Validation Accuracy: 0.7096\n",
      "Epoch 2 - Accuracy: 0.8619, Validation Accuracy: 0.7147\n",
      "Epoch 3 - Accuracy: 0.9150, Validation Accuracy: 0.7209\n",
      "Epoch 4 - Accuracy: 0.9271, Validation Accuracy: 0.7209\n",
      "Epoch 5 - Accuracy: 0.9338, Validation Accuracy: 0.7044\n",
      "Epoch 6 - Accuracy: 0.9284, Validation Accuracy: 0.7044\n",
      "Epoch 7 - Accuracy: 0.9317, Validation Accuracy: 0.6993\n",
      "Epoch 8 - Accuracy: 0.9279, Validation Accuracy: 0.7085\n",
      "Epoch 9 - Accuracy: 0.9258, Validation Accuracy: 0.7055\n",
      "Epoch 10 - Accuracy: 0.9238, Validation Accuracy: 0.6982\n",
      "\n",
      "Hamming Loss: 0.09861143798540833\n"
     ]
    }
   ],
   "source": [
    "# Get accuracy and validation accuracy\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Print the accuracy and validation accuracy for each epoch\n",
    "for epoch in range(len(accuracy)):\n",
    "    print(f\"Epoch {epoch + 1} - Accuracy: {accuracy[epoch]:.4f}, Validation Accuracy: {val_accuracy[epoch]:.4f}\")\n",
    "    \n",
    "# Print hamming loss\n",
    "print(\"\\nHamming Loss:\", hamming_loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5693ac3",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Overall after experimenting with neurons and dense layer, the optimal model consists of 2 dense layers, one with 64 neurons and one with 32 neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fe28ea",
   "metadata": {},
   "source": [
    "# Regularisation\n",
    "\n",
    "By using Dropout, the model is less likely to overfit the training data, as the neurons become less sensitive to the specific training examples and learn more robust features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7498270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 0.4215 - accuracy: 0.4317 - val_loss: 0.2603 - val_accuracy: 0.6921\n",
      "Epoch 2/10\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 0.2682 - accuracy: 0.6808 - val_loss: 0.2261 - val_accuracy: 0.7281\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 0.2064 - accuracy: 0.7602 - val_loss: 0.2214 - val_accuracy: 0.7240\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.1602 - accuracy: 0.8168 - val_loss: 0.2284 - val_accuracy: 0.7394\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.1341 - accuracy: 0.8555 - val_loss: 0.2304 - val_accuracy: 0.7261\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.1154 - accuracy: 0.8774 - val_loss: 0.2429 - val_accuracy: 0.7333\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.1026 - accuracy: 0.8849 - val_loss: 0.2548 - val_accuracy: 0.7353\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0911 - accuracy: 0.8895 - val_loss: 0.2634 - val_accuracy: 0.7333\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.0859 - accuracy: 0.8941 - val_loss: 0.2789 - val_accuracy: 0.7333\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.0762 - accuracy: 0.9037 - val_loss: 0.2898 - val_accuracy: 0.7415\n",
      "38/38 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train_dense.shape[1],)))\n",
    "model.add(Dropout(0.3))  # Add a dropout layer after the first hidden layer with a dropout rate of 0.3 (30%)\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))  # Add another dropout layer after the second hidden layer with a dropout rate of 0.2 (20%)\n",
    "model.add(Dense(y.shape[1], activation='sigmoid')) # Use sigmoid activation for multi-label classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_dense, y_train, batch_size=32, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_proba = model.predict(X_test_dense)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "hamming_loss_value = hamming_loss(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b986cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Accuracy: 0.4317, Validation Accuracy: 0.6921\n",
      "Epoch 2 - Accuracy: 0.6808, Validation Accuracy: 0.7281\n",
      "Epoch 3 - Accuracy: 0.7602, Validation Accuracy: 0.7240\n",
      "Epoch 4 - Accuracy: 0.8168, Validation Accuracy: 0.7394\n",
      "Epoch 5 - Accuracy: 0.8555, Validation Accuracy: 0.7261\n",
      "Epoch 6 - Accuracy: 0.8774, Validation Accuracy: 0.7333\n",
      "Epoch 7 - Accuracy: 0.8849, Validation Accuracy: 0.7353\n",
      "Epoch 8 - Accuracy: 0.8895, Validation Accuracy: 0.7333\n",
      "Epoch 9 - Accuracy: 0.8941, Validation Accuracy: 0.7333\n",
      "Epoch 10 - Accuracy: 0.9037, Validation Accuracy: 0.7415\n",
      "\n",
      "Hamming Loss: 0.08943280771946341\n"
     ]
    }
   ],
   "source": [
    "# Get accuracy and validation accuracy\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Print the accuracy and validation accuracy for each epoch\n",
    "for epoch in range(len(accuracy)):\n",
    "    print(f\"Epoch {epoch + 1} - Accuracy: {accuracy[epoch]:.4f}, Validation Accuracy: {val_accuracy[epoch]:.4f}\")\n",
    "    \n",
    "# Print hamming loss\n",
    "print(\"\\nHamming Loss:\", hamming_loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddfcd81",
   "metadata": {},
   "source": [
    "## L1 Regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58a139d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 11.8432 - accuracy: 0.5314 - val_loss: 3.0411 - val_accuracy: 0.5829\n",
      "Epoch 2/10\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 2.5224 - accuracy: 0.5438 - val_loss: 2.1848 - val_accuracy: 0.5747\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - 2s 16ms/step - loss: 2.1172 - accuracy: 0.5546 - val_loss: 2.1049 - val_accuracy: 0.5778\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 2.0574 - accuracy: 0.5677 - val_loss: 2.0335 - val_accuracy: 0.5870\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - 2s 14ms/step - loss: 2.0346 - accuracy: 0.5755 - val_loss: 2.0426 - val_accuracy: 0.5850\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.0266 - accuracy: 0.5814 - val_loss: 2.0515 - val_accuracy: 0.5695\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.0211 - accuracy: 0.5817 - val_loss: 2.0356 - val_accuracy: 0.5860\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.0178 - accuracy: 0.5863 - val_loss: 2.0080 - val_accuracy: 0.5808\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 2.0154 - accuracy: 0.5891 - val_loss: 2.0392 - val_accuracy: 0.5726\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 2.0161 - accuracy: 0.5832 - val_loss: 1.9918 - val_accuracy: 0.5860\n",
      "38/38 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train_dense.shape[1],), kernel_regularizer=l1(0.01)))\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=l1(0.01)))\n",
    "model.add(Dense(y.shape[1], activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_dense, y_train, batch_size=32, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_proba = model.predict(X_test_dense)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "hamming_loss_value = hamming_loss(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62faeaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Accuracy: 0.5314, Validation Accuracy: 0.5829\n",
      "Epoch 2 - Accuracy: 0.5438, Validation Accuracy: 0.5747\n",
      "Epoch 3 - Accuracy: 0.5546, Validation Accuracy: 0.5778\n",
      "Epoch 4 - Accuracy: 0.5677, Validation Accuracy: 0.5870\n",
      "Epoch 5 - Accuracy: 0.5755, Validation Accuracy: 0.5850\n",
      "Epoch 6 - Accuracy: 0.5814, Validation Accuracy: 0.5695\n",
      "Epoch 7 - Accuracy: 0.5817, Validation Accuracy: 0.5860\n",
      "Epoch 8 - Accuracy: 0.5863, Validation Accuracy: 0.5808\n",
      "Epoch 9 - Accuracy: 0.5891, Validation Accuracy: 0.5726\n",
      "Epoch 10 - Accuracy: 0.5832, Validation Accuracy: 0.5860\n",
      "\n",
      "Hamming Loss: 0.12473523181925159\n"
     ]
    }
   ],
   "source": [
    "# Get accuracy and validation accuracy\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Print the accuracy and validation accuracy for each epoch\n",
    "for epoch in range(len(accuracy)):\n",
    "    print(f\"Epoch {epoch + 1} - Accuracy: {accuracy[epoch]:.4f}, Validation Accuracy: {val_accuracy[epoch]:.4f}\")\n",
    "    \n",
    "# Print hamming loss\n",
    "print(\"\\nHamming Loss:\", hamming_loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4054aed",
   "metadata": {},
   "source": [
    "## L2 Regularosation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91f0166c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 0.6740 - accuracy: 0.6690 - val_loss: 0.4804 - val_accuracy: 0.7168\n",
      "Epoch 2/10\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 0.3590 - accuracy: 0.7957 - val_loss: 0.3911 - val_accuracy: 0.7147\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.2934 - accuracy: 0.8150 - val_loss: 0.3700 - val_accuracy: 0.7219\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.2697 - accuracy: 0.8241 - val_loss: 0.3565 - val_accuracy: 0.7158\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.2601 - accuracy: 0.8266 - val_loss: 0.3507 - val_accuracy: 0.7106\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 0.2500 - accuracy: 0.8228 - val_loss: 0.3494 - val_accuracy: 0.7034\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.2412 - accuracy: 0.8326 - val_loss: 0.3443 - val_accuracy: 0.7106\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.2407 - accuracy: 0.8279 - val_loss: 0.3641 - val_accuracy: 0.7137\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.2383 - accuracy: 0.8300 - val_loss: 0.3406 - val_accuracy: 0.7127\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.2297 - accuracy: 0.8387 - val_loss: 0.3457 - val_accuracy: 0.7096\n",
      "38/38 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train_dense.shape[1],), kernel_regularizer=l2(0.01)))\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dense(y.shape[1], activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_dense, y_train, batch_size=32, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_proba = model.predict(X_test_dense)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "hamming_loss_value = hamming_loss(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f13d43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Accuracy: 0.6690, Validation Accuracy: 0.7168\n",
      "Epoch 2 - Accuracy: 0.7957, Validation Accuracy: 0.7147\n",
      "Epoch 3 - Accuracy: 0.8150, Validation Accuracy: 0.7219\n",
      "Epoch 4 - Accuracy: 0.8241, Validation Accuracy: 0.7158\n",
      "Epoch 5 - Accuracy: 0.8266, Validation Accuracy: 0.7106\n",
      "Epoch 6 - Accuracy: 0.8228, Validation Accuracy: 0.7034\n",
      "Epoch 7 - Accuracy: 0.8326, Validation Accuracy: 0.7106\n",
      "Epoch 8 - Accuracy: 0.8279, Validation Accuracy: 0.7137\n",
      "Epoch 9 - Accuracy: 0.8300, Validation Accuracy: 0.7127\n",
      "Epoch 10 - Accuracy: 0.8387, Validation Accuracy: 0.7096\n",
      "\n",
      "Hamming Loss: 0.09366909861143799\n"
     ]
    }
   ],
   "source": [
    "# Get accuracy and validation accuracy\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Print the accuracy and validation accuracy for each epoch\n",
    "for epoch in range(len(accuracy)):\n",
    "    print(f\"Epoch {epoch + 1} - Accuracy: {accuracy[epoch]:.4f}, Validation Accuracy: {val_accuracy[epoch]:.4f}\")\n",
    "    \n",
    "# Print hamming loss\n",
    "print(\"\\nHamming Loss:\", hamming_loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639b5b46",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Use of dropout does increase the accuracy slightly and makes overfitting less likey, I will use this as both l1 and l2 reguarisation decreases the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5117333",
   "metadata": {},
   "source": [
    "# Experimenting with different activation functions\n",
    "\n",
    "The following activation functions will be tested:\n",
    "- relu\n",
    "- elu\n",
    "- selu\n",
    "- tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07818396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Activation Function: relu\n",
      "Epoch 1/10\n",
      "122/122 [==============================] - 2s 11ms/step - loss: 0.3944 - accuracy: 0.5077 - val_loss: 0.2648 - val_accuracy: 0.6766\n",
      "Epoch 2/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.2617 - accuracy: 0.6770 - val_loss: 0.2353 - val_accuracy: 0.7199\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.1989 - accuracy: 0.7609 - val_loss: 0.2367 - val_accuracy: 0.7147\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.1567 - accuracy: 0.8107 - val_loss: 0.2431 - val_accuracy: 0.7147\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.1295 - accuracy: 0.8442 - val_loss: 0.2512 - val_accuracy: 0.7219\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.1163 - accuracy: 0.8722 - val_loss: 0.2581 - val_accuracy: 0.7199\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0956 - accuracy: 0.8846 - val_loss: 0.2702 - val_accuracy: 0.7178\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0861 - accuracy: 0.8897 - val_loss: 0.2832 - val_accuracy: 0.7209\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.0780 - accuracy: 0.8941 - val_loss: 0.3020 - val_accuracy: 0.7199\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.0725 - accuracy: 0.8982 - val_loss: 0.3119 - val_accuracy: 0.7250\n",
      "38/38 [==============================] - 0s 5ms/step\n",
      "Epoch 1 - Accuracy: 0.5077, Validation Accuracy: 0.6766\n",
      "Epoch 2 - Accuracy: 0.6770, Validation Accuracy: 0.7199\n",
      "Epoch 3 - Accuracy: 0.7609, Validation Accuracy: 0.7147\n",
      "Epoch 4 - Accuracy: 0.8107, Validation Accuracy: 0.7147\n",
      "Epoch 5 - Accuracy: 0.8442, Validation Accuracy: 0.7219\n",
      "Epoch 6 - Accuracy: 0.8722, Validation Accuracy: 0.7199\n",
      "Epoch 7 - Accuracy: 0.8846, Validation Accuracy: 0.7178\n",
      "Epoch 8 - Accuracy: 0.8897, Validation Accuracy: 0.7209\n",
      "Epoch 9 - Accuracy: 0.8941, Validation Accuracy: 0.7199\n",
      "Epoch 10 - Accuracy: 0.8982, Validation Accuracy: 0.7250\n",
      "\n",
      "Hamming Loss: 0.08872675923746765\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Testing Activation Function: elu\n",
      "Epoch 1/10\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 0.3433 - accuracy: 0.5909 - val_loss: 0.2262 - val_accuracy: 0.7374\n",
      "Epoch 2/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.2089 - accuracy: 0.7615 - val_loss: 0.2244 - val_accuracy: 0.7415\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.1469 - accuracy: 0.8344 - val_loss: 0.2379 - val_accuracy: 0.7281\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.1115 - accuracy: 0.8797 - val_loss: 0.2539 - val_accuracy: 0.7271\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0865 - accuracy: 0.8928 - val_loss: 0.2848 - val_accuracy: 0.7178\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0680 - accuracy: 0.9145 - val_loss: 0.2995 - val_accuracy: 0.7240\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 0.0552 - accuracy: 0.9122 - val_loss: 0.3278 - val_accuracy: 0.7281\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0504 - accuracy: 0.9132 - val_loss: 0.3466 - val_accuracy: 0.7219\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.0455 - accuracy: 0.9227 - val_loss: 0.3599 - val_accuracy: 0.7250\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0405 - accuracy: 0.9204 - val_loss: 0.3722 - val_accuracy: 0.7230\n",
      "38/38 [==============================] - 0s 3ms/step\n",
      "Epoch 1 - Accuracy: 0.5909, Validation Accuracy: 0.7374\n",
      "Epoch 2 - Accuracy: 0.7615, Validation Accuracy: 0.7415\n",
      "Epoch 3 - Accuracy: 0.8344, Validation Accuracy: 0.7281\n",
      "Epoch 4 - Accuracy: 0.8797, Validation Accuracy: 0.7271\n",
      "Epoch 5 - Accuracy: 0.8928, Validation Accuracy: 0.7178\n",
      "Epoch 6 - Accuracy: 0.9145, Validation Accuracy: 0.7240\n",
      "Epoch 7 - Accuracy: 0.9122, Validation Accuracy: 0.7281\n",
      "Epoch 8 - Accuracy: 0.9132, Validation Accuracy: 0.7219\n",
      "Epoch 9 - Accuracy: 0.9227, Validation Accuracy: 0.7250\n",
      "Epoch 10 - Accuracy: 0.9204, Validation Accuracy: 0.7230\n",
      "\n",
      "Hamming Loss: 0.09049188044245705\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Testing Activation Function: selu\n",
      "Epoch 1/10\n",
      "122/122 [==============================] - 2s 11ms/step - loss: 0.3656 - accuracy: 0.5850 - val_loss: 0.2377 - val_accuracy: 0.7044\n",
      "Epoch 2/10\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.2176 - accuracy: 0.7635 - val_loss: 0.2297 - val_accuracy: 0.7291\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.1547 - accuracy: 0.8282 - val_loss: 0.2398 - val_accuracy: 0.7240\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.1179 - accuracy: 0.8730 - val_loss: 0.2544 - val_accuracy: 0.7188\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.0963 - accuracy: 0.8936 - val_loss: 0.2725 - val_accuracy: 0.7261\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.0792 - accuracy: 0.9057 - val_loss: 0.2901 - val_accuracy: 0.7116\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.0676 - accuracy: 0.9078 - val_loss: 0.3105 - val_accuracy: 0.7178\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 0.0568 - accuracy: 0.9176 - val_loss: 0.3328 - val_accuracy: 0.7219\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0496 - accuracy: 0.9258 - val_loss: 0.3478 - val_accuracy: 0.7240\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0490 - accuracy: 0.9191 - val_loss: 0.3816 - val_accuracy: 0.7116\n",
      "38/38 [==============================] - 0s 3ms/step\n",
      "Epoch 1 - Accuracy: 0.5850, Validation Accuracy: 0.7044\n",
      "Epoch 2 - Accuracy: 0.7635, Validation Accuracy: 0.7291\n",
      "Epoch 3 - Accuracy: 0.8282, Validation Accuracy: 0.7240\n",
      "Epoch 4 - Accuracy: 0.8730, Validation Accuracy: 0.7188\n",
      "Epoch 5 - Accuracy: 0.8936, Validation Accuracy: 0.7261\n",
      "Epoch 6 - Accuracy: 0.9057, Validation Accuracy: 0.7116\n",
      "Epoch 7 - Accuracy: 0.9078, Validation Accuracy: 0.7178\n",
      "Epoch 8 - Accuracy: 0.9176, Validation Accuracy: 0.7219\n",
      "Epoch 9 - Accuracy: 0.9258, Validation Accuracy: 0.7240\n",
      "Epoch 10 - Accuracy: 0.9191, Validation Accuracy: 0.7116\n",
      "\n",
      "Hamming Loss: 0.09261002588844434\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Testing Activation Function: tanh\n",
      "Epoch 1/10\n",
      "122/122 [==============================] - 2s 10ms/step - loss: 0.3334 - accuracy: 0.5791 - val_loss: 0.2471 - val_accuracy: 0.6993\n",
      "Epoch 2/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.2251 - accuracy: 0.7545 - val_loss: 0.2170 - val_accuracy: 0.7374\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - 2s 13ms/step - loss: 0.1755 - accuracy: 0.8253 - val_loss: 0.2160 - val_accuracy: 0.7261\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.1378 - accuracy: 0.8738 - val_loss: 0.2158 - val_accuracy: 0.7322\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.1135 - accuracy: 0.8962 - val_loss: 0.2206 - val_accuracy: 0.7240\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.0938 - accuracy: 0.9119 - val_loss: 0.2294 - val_accuracy: 0.7147\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0774 - accuracy: 0.9181 - val_loss: 0.2419 - val_accuracy: 0.7065\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.0666 - accuracy: 0.9258 - val_loss: 0.2511 - val_accuracy: 0.7230\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.0600 - accuracy: 0.9245 - val_loss: 0.2590 - val_accuracy: 0.7188\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0526 - accuracy: 0.9245 - val_loss: 0.2670 - val_accuracy: 0.7168\n",
      "38/38 [==============================] - 1s 9ms/step\n",
      "Epoch 1 - Accuracy: 0.5791, Validation Accuracy: 0.6993\n",
      "Epoch 2 - Accuracy: 0.7545, Validation Accuracy: 0.7374\n",
      "Epoch 3 - Accuracy: 0.8253, Validation Accuracy: 0.7261\n",
      "Epoch 4 - Accuracy: 0.8738, Validation Accuracy: 0.7322\n",
      "Epoch 5 - Accuracy: 0.8962, Validation Accuracy: 0.7240\n",
      "Epoch 6 - Accuracy: 0.9119, Validation Accuracy: 0.7147\n",
      "Epoch 7 - Accuracy: 0.9181, Validation Accuracy: 0.7065\n",
      "Epoch 8 - Accuracy: 0.9258, Validation Accuracy: 0.7230\n",
      "Epoch 9 - Accuracy: 0.9245, Validation Accuracy: 0.7188\n",
      "Epoch 10 - Accuracy: 0.9245, Validation Accuracy: 0.7168\n",
      "\n",
      "Hamming Loss: 0.09131560367145211\n",
      "\n",
      "-----------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of activation functions to test\n",
    "activation_functions = ['relu', 'elu', 'selu', 'tanh']\n",
    "\n",
    "for activation_func in activation_functions:\n",
    "    print(f\"Testing Activation Function: {activation_func}\")\n",
    "\n",
    "    # Build model with the current activation function\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation=activation_func, input_shape=(X_train_dense.shape[1],)))\n",
    "    model.add(Dropout(0.3)) \n",
    "    model.add(Dense(32, activation=activation_func))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(y.shape[1], activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train_dense, y_train, batch_size=32, epochs=10, validation_split=0.2)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred_proba = model.predict(X_test_dense)\n",
    "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "    # Evaluate the model\n",
    "    hamming_loss_value = hamming_loss(y_test, y_pred)\n",
    "\n",
    "    # Get accuracy and validation accuracy\n",
    "    accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "    # Print the accuracy and validation accuracy for each epoch\n",
    "    for epoch in range(len(accuracy)):\n",
    "        print(f\"Epoch {epoch + 1} - Accuracy: {accuracy[epoch]:.4f}, Validation Accuracy: {val_accuracy[epoch]:.4f}\")\n",
    "\n",
    "    # Print hamming loss\n",
    "    print(\"\\nHamming Loss:\", hamming_loss_value)\n",
    "\n",
    "    print(\"\\n-----------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083dc666",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "Based on the accuracy, relu proved to be the best activation function, followed by elu, selu and tanh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7dc20c",
   "metadata": {},
   "source": [
    "# Learning rates and Optimisers\n",
    "\n",
    "The following learning rates will be experimented:\n",
    "- 0.001\n",
    "- 0.01\n",
    "- 0.1\n",
    "\n",
    "The following optimisers will be experimented:\n",
    "- adam\n",
    "- sdg\n",
    "- rmsprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adaca13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Learning Rate: 0.001, Optimizer: adam\n",
      "Epoch 1/10\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 0.3438 - accuracy: 0.5523 - val_loss: 0.2479 - val_accuracy: 0.7024\n",
      "Epoch 2/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.2305 - accuracy: 0.7566 - val_loss: 0.2183 - val_accuracy: 0.7281\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.1752 - accuracy: 0.8326 - val_loss: 0.2075 - val_accuracy: 0.7219\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.1363 - accuracy: 0.8707 - val_loss: 0.2103 - val_accuracy: 0.7333\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.1118 - accuracy: 0.8921 - val_loss: 0.2139 - val_accuracy: 0.7137\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0929 - accuracy: 0.9080 - val_loss: 0.2215 - val_accuracy: 0.7302\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0793 - accuracy: 0.9158 - val_loss: 0.2290 - val_accuracy: 0.7199\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.0704 - accuracy: 0.9204 - val_loss: 0.2412 - val_accuracy: 0.7230\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.0608 - accuracy: 0.9194 - val_loss: 0.2495 - val_accuracy: 0.7178\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.0557 - accuracy: 0.9196 - val_loss: 0.2533 - val_accuracy: 0.7209\n",
      "38/38 [==============================] - 0s 3ms/step\n",
      "Epoch 1 - Accuracy: 0.5523, Validation Accuracy: 0.7024\n",
      "Epoch 2 - Accuracy: 0.7566, Validation Accuracy: 0.7281\n",
      "Epoch 3 - Accuracy: 0.8326, Validation Accuracy: 0.7219\n",
      "Epoch 4 - Accuracy: 0.8707, Validation Accuracy: 0.7333\n",
      "Epoch 5 - Accuracy: 0.8921, Validation Accuracy: 0.7137\n",
      "Epoch 6 - Accuracy: 0.9080, Validation Accuracy: 0.7302\n",
      "Epoch 7 - Accuracy: 0.9158, Validation Accuracy: 0.7199\n",
      "Epoch 8 - Accuracy: 0.9204, Validation Accuracy: 0.7230\n",
      "Epoch 9 - Accuracy: 0.9194, Validation Accuracy: 0.7178\n",
      "Epoch 10 - Accuracy: 0.9196, Validation Accuracy: 0.7209\n",
      "\n",
      "Hamming Loss: 0.09178630265944929\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Testing Learning Rate: 0.001, Optimizer: sgd\n",
      "Epoch 1/10\n",
      "122/122 [==============================] - 2s 10ms/step - loss: 0.5889 - accuracy: 0.2924 - val_loss: 0.4687 - val_accuracy: 0.4109\n",
      "Epoch 2/10\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.4857 - accuracy: 0.3588 - val_loss: 0.4293 - val_accuracy: 0.4531\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.4561 - accuracy: 0.3854 - val_loss: 0.4096 - val_accuracy: 0.4851\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.4398 - accuracy: 0.4158 - val_loss: 0.3960 - val_accuracy: 0.5057\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.4249 - accuracy: 0.4356 - val_loss: 0.3858 - val_accuracy: 0.5180\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.4160 - accuracy: 0.4637 - val_loss: 0.3774 - val_accuracy: 0.5232\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.4088 - accuracy: 0.4681 - val_loss: 0.3704 - val_accuracy: 0.5355\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.4010 - accuracy: 0.4766 - val_loss: 0.3646 - val_accuracy: 0.5458\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.3941 - accuracy: 0.4833 - val_loss: 0.3592 - val_accuracy: 0.5499\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.3867 - accuracy: 0.5059 - val_loss: 0.3546 - val_accuracy: 0.5551\n",
      "38/38 [==============================] - 0s 4ms/step\n",
      "Epoch 1 - Accuracy: 0.2924, Validation Accuracy: 0.4109\n",
      "Epoch 2 - Accuracy: 0.3588, Validation Accuracy: 0.4531\n",
      "Epoch 3 - Accuracy: 0.3854, Validation Accuracy: 0.4851\n",
      "Epoch 4 - Accuracy: 0.4158, Validation Accuracy: 0.5057\n",
      "Epoch 5 - Accuracy: 0.4356, Validation Accuracy: 0.5180\n",
      "Epoch 6 - Accuracy: 0.4637, Validation Accuracy: 0.5232\n",
      "Epoch 7 - Accuracy: 0.4681, Validation Accuracy: 0.5355\n",
      "Epoch 8 - Accuracy: 0.4766, Validation Accuracy: 0.5458\n",
      "Epoch 9 - Accuracy: 0.4833, Validation Accuracy: 0.5499\n",
      "Epoch 10 - Accuracy: 0.5059, Validation Accuracy: 0.5551\n",
      "\n",
      "Hamming Loss: 0.12791244998823253\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Testing Learning Rate: 0.001, Optimizer: rmsprop\n",
      "Epoch 1/10\n",
      "122/122 [==============================] - 2s 15ms/step - loss: 0.3289 - accuracy: 0.5822 - val_loss: 0.2539 - val_accuracy: 0.7085\n",
      "Epoch 2/10\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 0.2336 - accuracy: 0.7501 - val_loss: 0.2234 - val_accuracy: 0.7353\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.1811 - accuracy: 0.8163 - val_loss: 0.2169 - val_accuracy: 0.7425\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.1479 - accuracy: 0.8478 - val_loss: 0.2162 - val_accuracy: 0.7302\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.1235 - accuracy: 0.8743 - val_loss: 0.2238 - val_accuracy: 0.7343\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.1023 - accuracy: 0.8874 - val_loss: 0.2375 - val_accuracy: 0.7250\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0904 - accuracy: 0.9024 - val_loss: 0.2445 - val_accuracy: 0.7240\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0776 - accuracy: 0.9008 - val_loss: 0.2512 - val_accuracy: 0.7230\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0675 - accuracy: 0.9116 - val_loss: 0.2675 - val_accuracy: 0.7188\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0594 - accuracy: 0.9219 - val_loss: 0.2769 - val_accuracy: 0.7188\n",
      "38/38 [==============================] - 0s 3ms/step\n",
      "Epoch 1 - Accuracy: 0.5822, Validation Accuracy: 0.7085\n",
      "Epoch 2 - Accuracy: 0.7501, Validation Accuracy: 0.7353\n",
      "Epoch 3 - Accuracy: 0.8163, Validation Accuracy: 0.7425\n",
      "Epoch 4 - Accuracy: 0.8478, Validation Accuracy: 0.7302\n",
      "Epoch 5 - Accuracy: 0.8743, Validation Accuracy: 0.7343\n",
      "Epoch 6 - Accuracy: 0.8874, Validation Accuracy: 0.7250\n",
      "Epoch 7 - Accuracy: 0.9024, Validation Accuracy: 0.7240\n",
      "Epoch 8 - Accuracy: 0.9008, Validation Accuracy: 0.7230\n",
      "Epoch 9 - Accuracy: 0.9116, Validation Accuracy: 0.7188\n",
      "Epoch 10 - Accuracy: 0.9219, Validation Accuracy: 0.7188\n",
      "\n",
      "Hamming Loss: 0.09237467639444576\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Testing Learning Rate: 0.01, Optimizer: adam\n",
      "Epoch 1/10\n",
      "122/122 [==============================] - 2s 10ms/step - loss: 0.3359 - accuracy: 0.5430 - val_loss: 0.2690 - val_accuracy: 0.6395\n",
      "Epoch 2/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.2774 - accuracy: 0.6381 - val_loss: 0.2492 - val_accuracy: 0.6632\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.2569 - accuracy: 0.6708 - val_loss: 0.2431 - val_accuracy: 0.6746\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.2419 - accuracy: 0.7032 - val_loss: 0.2415 - val_accuracy: 0.6869\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.2272 - accuracy: 0.7208 - val_loss: 0.2374 - val_accuracy: 0.6797\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.2253 - accuracy: 0.7367 - val_loss: 0.2396 - val_accuracy: 0.7003\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.2189 - accuracy: 0.7339 - val_loss: 0.2388 - val_accuracy: 0.6962\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.2088 - accuracy: 0.7607 - val_loss: 0.2332 - val_accuracy: 0.6993\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.2076 - accuracy: 0.7463 - val_loss: 0.2298 - val_accuracy: 0.6941\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.2042 - accuracy: 0.7576 - val_loss: 0.2331 - val_accuracy: 0.7106\n",
      "38/38 [==============================] - 0s 3ms/step\n",
      "Epoch 1 - Accuracy: 0.5430, Validation Accuracy: 0.6395\n",
      "Epoch 2 - Accuracy: 0.6381, Validation Accuracy: 0.6632\n",
      "Epoch 3 - Accuracy: 0.6708, Validation Accuracy: 0.6746\n",
      "Epoch 4 - Accuracy: 0.7032, Validation Accuracy: 0.6869\n",
      "Epoch 5 - Accuracy: 0.7208, Validation Accuracy: 0.6797\n",
      "Epoch 6 - Accuracy: 0.7367, Validation Accuracy: 0.7003\n",
      "Epoch 7 - Accuracy: 0.7339, Validation Accuracy: 0.6962\n",
      "Epoch 8 - Accuracy: 0.7607, Validation Accuracy: 0.6993\n",
      "Epoch 9 - Accuracy: 0.7463, Validation Accuracy: 0.6941\n",
      "Epoch 10 - Accuracy: 0.7576, Validation Accuracy: 0.7106\n",
      "\n",
      "Hamming Loss: 0.09331607437044011\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Testing Learning Rate: 0.01, Optimizer: sgd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "122/122 [==============================] - 2s 10ms/step - loss: 0.4317 - accuracy: 0.4024 - val_loss: 0.3430 - val_accuracy: 0.5726\n",
      "Epoch 2/10\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 0.3624 - accuracy: 0.5312 - val_loss: 0.3158 - val_accuracy: 0.6262\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.3352 - accuracy: 0.5860 - val_loss: 0.3020 - val_accuracy: 0.6385\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.3153 - accuracy: 0.6262 - val_loss: 0.2891 - val_accuracy: 0.6540\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.2996 - accuracy: 0.6561 - val_loss: 0.2791 - val_accuracy: 0.6632\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.2909 - accuracy: 0.6726 - val_loss: 0.2726 - val_accuracy: 0.6735\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.2781 - accuracy: 0.6927 - val_loss: 0.2654 - val_accuracy: 0.6941\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.2692 - accuracy: 0.7117 - val_loss: 0.2614 - val_accuracy: 0.7024\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.2593 - accuracy: 0.7210 - val_loss: 0.2566 - val_accuracy: 0.6952\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.2529 - accuracy: 0.7202 - val_loss: 0.2529 - val_accuracy: 0.7013\n",
      "38/38 [==============================] - 0s 3ms/step\n",
      "Epoch 1 - Accuracy: 0.4024, Validation Accuracy: 0.5726\n",
      "Epoch 2 - Accuracy: 0.5312, Validation Accuracy: 0.6262\n",
      "Epoch 3 - Accuracy: 0.5860, Validation Accuracy: 0.6385\n",
      "Epoch 4 - Accuracy: 0.6262, Validation Accuracy: 0.6540\n",
      "Epoch 5 - Accuracy: 0.6561, Validation Accuracy: 0.6632\n",
      "Epoch 6 - Accuracy: 0.6726, Validation Accuracy: 0.6735\n",
      "Epoch 7 - Accuracy: 0.6927, Validation Accuracy: 0.6941\n",
      "Epoch 8 - Accuracy: 0.7117, Validation Accuracy: 0.7024\n",
      "Epoch 9 - Accuracy: 0.7210, Validation Accuracy: 0.6952\n",
      "Epoch 10 - Accuracy: 0.7202, Validation Accuracy: 0.7013\n",
      "\n",
      "Hamming Loss: 0.09896446222640622\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Testing Learning Rate: 0.01, Optimizer: rmsprop\n",
      "Epoch 1/10\n",
      "122/122 [==============================] - 3s 17ms/step - loss: 0.3313 - accuracy: 0.5520 - val_loss: 0.2581 - val_accuracy: 0.6571\n",
      "Epoch 2/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.2613 - accuracy: 0.6734 - val_loss: 0.2333 - val_accuracy: 0.7085\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.2315 - accuracy: 0.7275 - val_loss: 0.2405 - val_accuracy: 0.6941\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.2157 - accuracy: 0.7486 - val_loss: 0.2305 - val_accuracy: 0.7013\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.2007 - accuracy: 0.7674 - val_loss: 0.2351 - val_accuracy: 0.7240\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.1950 - accuracy: 0.7767 - val_loss: 0.2384 - val_accuracy: 0.7158\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.1863 - accuracy: 0.7880 - val_loss: 0.2334 - val_accuracy: 0.7209\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.1789 - accuracy: 0.7986 - val_loss: 0.2305 - val_accuracy: 0.7106\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.1759 - accuracy: 0.8068 - val_loss: 0.2296 - val_accuracy: 0.7302\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 0.1726 - accuracy: 0.8081 - val_loss: 0.2337 - val_accuracy: 0.7261\n",
      "38/38 [==============================] - 0s 6ms/step\n",
      "Epoch 1 - Accuracy: 0.5520, Validation Accuracy: 0.6571\n",
      "Epoch 2 - Accuracy: 0.6734, Validation Accuracy: 0.7085\n",
      "Epoch 3 - Accuracy: 0.7275, Validation Accuracy: 0.6941\n",
      "Epoch 4 - Accuracy: 0.7486, Validation Accuracy: 0.7013\n",
      "Epoch 5 - Accuracy: 0.7674, Validation Accuracy: 0.7240\n",
      "Epoch 6 - Accuracy: 0.7767, Validation Accuracy: 0.7158\n",
      "Epoch 7 - Accuracy: 0.7880, Validation Accuracy: 0.7209\n",
      "Epoch 8 - Accuracy: 0.7986, Validation Accuracy: 0.7106\n",
      "Epoch 9 - Accuracy: 0.8068, Validation Accuracy: 0.7302\n",
      "Epoch 10 - Accuracy: 0.8081, Validation Accuracy: 0.7261\n",
      "\n",
      "Hamming Loss: 0.08813838550247118\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Testing Learning Rate: 0.1, Optimizer: adam\n",
      "Epoch 1/10\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 0.4185 - accuracy: 0.4080 - val_loss: 0.4101 - val_accuracy: 0.2461\n",
      "Epoch 2/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.3953 - accuracy: 0.4261 - val_loss: 0.3578 - val_accuracy: 0.5376\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.3986 - accuracy: 0.4268 - val_loss: 0.3936 - val_accuracy: 0.2997\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.4062 - accuracy: 0.4199 - val_loss: 0.3748 - val_accuracy: 0.4634\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.3968 - accuracy: 0.4418 - val_loss: 0.3916 - val_accuracy: 0.4789\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.3904 - accuracy: 0.4472 - val_loss: 0.3623 - val_accuracy: 0.4552\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.3992 - accuracy: 0.4152 - val_loss: 0.3609 - val_accuracy: 0.4882\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.3884 - accuracy: 0.4395 - val_loss: 0.3903 - val_accuracy: 0.4954\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.3753 - accuracy: 0.4681 - val_loss: 0.3388 - val_accuracy: 0.5530\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.3780 - accuracy: 0.4701 - val_loss: 0.3426 - val_accuracy: 0.5108\n",
      "38/38 [==============================] - 0s 4ms/step\n",
      "Epoch 1 - Accuracy: 0.4080, Validation Accuracy: 0.2461\n",
      "Epoch 2 - Accuracy: 0.4261, Validation Accuracy: 0.5376\n",
      "Epoch 3 - Accuracy: 0.4268, Validation Accuracy: 0.2997\n",
      "Epoch 4 - Accuracy: 0.4199, Validation Accuracy: 0.4634\n",
      "Epoch 5 - Accuracy: 0.4418, Validation Accuracy: 0.4789\n",
      "Epoch 6 - Accuracy: 0.4472, Validation Accuracy: 0.4552\n",
      "Epoch 7 - Accuracy: 0.4152, Validation Accuracy: 0.4882\n",
      "Epoch 8 - Accuracy: 0.4395, Validation Accuracy: 0.4954\n",
      "Epoch 9 - Accuracy: 0.4681, Validation Accuracy: 0.5530\n",
      "Epoch 10 - Accuracy: 0.4701, Validation Accuracy: 0.5108\n",
      "\n",
      "Hamming Loss: 0.14615203577312308\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Testing Learning Rate: 0.1, Optimizer: sgd\n",
      "Epoch 1/10\n",
      "122/122 [==============================] - 2s 10ms/step - loss: 0.3505 - accuracy: 0.5260 - val_loss: 0.2756 - val_accuracy: 0.6344\n",
      "Epoch 2/10\n",
      "122/122 [==============================] - 1s 6ms/step - loss: 0.2830 - accuracy: 0.6461 - val_loss: 0.2509 - val_accuracy: 0.6859\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.2517 - accuracy: 0.6945 - val_loss: 0.2394 - val_accuracy: 0.6962\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.2333 - accuracy: 0.7213 - val_loss: 0.2360 - val_accuracy: 0.6952\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.2179 - accuracy: 0.7463 - val_loss: 0.2283 - val_accuracy: 0.7178\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.2010 - accuracy: 0.7640 - val_loss: 0.2387 - val_accuracy: 0.6910\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.1876 - accuracy: 0.7895 - val_loss: 0.2317 - val_accuracy: 0.7116\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.1753 - accuracy: 0.8096 - val_loss: 0.2209 - val_accuracy: 0.7230\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.1672 - accuracy: 0.8163 - val_loss: 0.2212 - val_accuracy: 0.7147\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - 1s 7ms/step - loss: 0.1558 - accuracy: 0.8302 - val_loss: 0.2265 - val_accuracy: 0.7024\n",
      "38/38 [==============================] - 0s 3ms/step\n",
      "Epoch 1 - Accuracy: 0.5260, Validation Accuracy: 0.6344\n",
      "Epoch 2 - Accuracy: 0.6461, Validation Accuracy: 0.6859\n",
      "Epoch 3 - Accuracy: 0.6945, Validation Accuracy: 0.6962\n",
      "Epoch 4 - Accuracy: 0.7213, Validation Accuracy: 0.6952\n",
      "Epoch 5 - Accuracy: 0.7463, Validation Accuracy: 0.7178\n",
      "Epoch 6 - Accuracy: 0.7640, Validation Accuracy: 0.6910\n",
      "Epoch 7 - Accuracy: 0.7895, Validation Accuracy: 0.7116\n",
      "Epoch 8 - Accuracy: 0.8096, Validation Accuracy: 0.7230\n",
      "Epoch 9 - Accuracy: 0.8163, Validation Accuracy: 0.7147\n",
      "Epoch 10 - Accuracy: 0.8302, Validation Accuracy: 0.7024\n",
      "\n",
      "Hamming Loss: 0.08931513297246411\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Testing Learning Rate: 0.1, Optimizer: rmsprop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "122/122 [==============================] - 2s 11ms/step - loss: 0.5330 - accuracy: 0.3539 - val_loss: 0.6520 - val_accuracy: 0.1184\n",
      "Epoch 2/10\n",
      "122/122 [==============================] - 1s 8ms/step - loss: 0.4542 - accuracy: 0.4191 - val_loss: 0.4393 - val_accuracy: 0.3079\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.4451 - accuracy: 0.4387 - val_loss: 0.5712 - val_accuracy: 0.4799\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.4371 - accuracy: 0.4449 - val_loss: 0.6017 - val_accuracy: 0.2729\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.4240 - accuracy: 0.4657 - val_loss: 0.3936 - val_accuracy: 0.5191\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.4081 - accuracy: 0.4879 - val_loss: 0.4166 - val_accuracy: 0.4655\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.4101 - accuracy: 0.4820 - val_loss: 0.5568 - val_accuracy: 0.4789\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.3986 - accuracy: 0.4956 - val_loss: 0.4251 - val_accuracy: 0.5129\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.4059 - accuracy: 0.4760 - val_loss: 0.4743 - val_accuracy: 0.4058\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.4146 - accuracy: 0.4773 - val_loss: 0.5505 - val_accuracy: 0.2678\n",
      "38/38 [==============================] - 0s 3ms/step\n",
      "Epoch 1 - Accuracy: 0.3539, Validation Accuracy: 0.1184\n",
      "Epoch 2 - Accuracy: 0.4191, Validation Accuracy: 0.3079\n",
      "Epoch 3 - Accuracy: 0.4387, Validation Accuracy: 0.4799\n",
      "Epoch 4 - Accuracy: 0.4449, Validation Accuracy: 0.2729\n",
      "Epoch 5 - Accuracy: 0.4657, Validation Accuracy: 0.5191\n",
      "Epoch 6 - Accuracy: 0.4879, Validation Accuracy: 0.4655\n",
      "Epoch 7 - Accuracy: 0.4820, Validation Accuracy: 0.4789\n",
      "Epoch 8 - Accuracy: 0.4956, Validation Accuracy: 0.5129\n",
      "Epoch 9 - Accuracy: 0.4760, Validation Accuracy: 0.4058\n",
      "Epoch 10 - Accuracy: 0.4773, Validation Accuracy: 0.2678\n",
      "\n",
      "Hamming Loss: 0.21440338903271358\n",
      "\n",
      "-----------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of learning rates and optimizers to test\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "optimizers = ['adam', 'sgd', 'rmsprop']\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for optimizer in optimizers:\n",
    "        print(f\"Testing Learning Rate: {lr}, Optimizer: {optimizer}\")\n",
    "\n",
    "        # Build model with the current learning rate and optimizer\n",
    "        model = Sequential()\n",
    "        model.add(Dense(64, activation=activation_func, input_shape=(X_train_dense.shape[1],)))\n",
    "        model.add(Dropout(0.3)) \n",
    "        model.add(Dense(32, activation=activation_func))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(y.shape[1], activation='sigmoid'))\n",
    "\n",
    "        if optimizer == 'adam':\n",
    "            optimizer = Adam(learning_rate=lr)\n",
    "        elif optimizer == 'sgd':\n",
    "            optimizer = SGD(learning_rate=lr)\n",
    "        elif optimizer == 'rmsprop':\n",
    "            optimizer = RMSprop(learning_rate=lr)\n",
    "\n",
    "        # Compile the model with the selected optimizer\n",
    "        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Train the model\n",
    "        history = model.fit(X_train_dense, y_train, batch_size=32, epochs=10, validation_split=0.2)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred_proba = model.predict(X_test_dense)\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "        # Evaluate the model\n",
    "        hamming_loss_value = hamming_loss(y_test, y_pred)\n",
    "\n",
    "        # Get accuracy and validation accuracy\n",
    "        accuracy = history.history['accuracy']\n",
    "        val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "        # Print the accuracy and validation accuracy for each epoch\n",
    "        for epoch in range(len(accuracy)):\n",
    "            print(f\"Epoch {epoch + 1} - Accuracy: {accuracy[epoch]:.4f}, Validation Accuracy: {val_accuracy[epoch]:.4f}\")\n",
    "\n",
    "        # Print hamming loss\n",
    "        print(\"\\nHamming Loss:\", hamming_loss_value)\n",
    "\n",
    "        print(\"\\n-----------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fd82bf",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "A learning rate of 0.001 and optimiser of rsmprop seems to be most prelevent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b651ba",
   "metadata": {},
   "source": [
    "# Batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60285be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Batch Size: 16\n",
      "Epoch 1/10\n",
      "243/243 [==============================] - 2s 8ms/step - loss: 0.3036 - accuracy: 0.6244 - val_loss: 0.2358 - val_accuracy: 0.7116\n",
      "Epoch 2/10\n",
      "243/243 [==============================] - 2s 7ms/step - loss: 0.2173 - accuracy: 0.7553 - val_loss: 0.2158 - val_accuracy: 0.7405\n",
      "Epoch 3/10\n",
      "243/243 [==============================] - 2s 7ms/step - loss: 0.1808 - accuracy: 0.8016 - val_loss: 0.2144 - val_accuracy: 0.7549\n",
      "Epoch 4/10\n",
      "243/243 [==============================] - 2s 7ms/step - loss: 0.1509 - accuracy: 0.8333 - val_loss: 0.2155 - val_accuracy: 0.7508\n",
      "Epoch 5/10\n",
      "243/243 [==============================] - 2s 7ms/step - loss: 0.1315 - accuracy: 0.8514 - val_loss: 0.2219 - val_accuracy: 0.7415\n",
      "Epoch 6/10\n",
      "243/243 [==============================] - 2s 7ms/step - loss: 0.1138 - accuracy: 0.8789 - val_loss: 0.2346 - val_accuracy: 0.7291\n",
      "Epoch 7/10\n",
      "243/243 [==============================] - 2s 10ms/step - loss: 0.0983 - accuracy: 0.8910 - val_loss: 0.2481 - val_accuracy: 0.7333\n",
      "Epoch 8/10\n",
      "243/243 [==============================] - 2s 9ms/step - loss: 0.0867 - accuracy: 0.8944 - val_loss: 0.2503 - val_accuracy: 0.7322\n",
      "Epoch 9/10\n",
      "243/243 [==============================] - 2s 7ms/step - loss: 0.0790 - accuracy: 0.8993 - val_loss: 0.2673 - val_accuracy: 0.7178\n",
      "Epoch 10/10\n",
      "243/243 [==============================] - 2s 7ms/step - loss: 0.0738 - accuracy: 0.9047 - val_loss: 0.2821 - val_accuracy: 0.7281\n",
      "38/38 [==============================] - 0s 3ms/step\n",
      "Epoch 1 - Accuracy: 0.6244, Validation Accuracy: 0.7116\n",
      "Epoch 2 - Accuracy: 0.7553, Validation Accuracy: 0.7405\n",
      "Epoch 3 - Accuracy: 0.8016, Validation Accuracy: 0.7549\n",
      "Epoch 4 - Accuracy: 0.8333, Validation Accuracy: 0.7508\n",
      "Epoch 5 - Accuracy: 0.8514, Validation Accuracy: 0.7415\n",
      "Epoch 6 - Accuracy: 0.8789, Validation Accuracy: 0.7291\n",
      "Epoch 7 - Accuracy: 0.8910, Validation Accuracy: 0.7333\n",
      "Epoch 8 - Accuracy: 0.8944, Validation Accuracy: 0.7322\n",
      "Epoch 9 - Accuracy: 0.8993, Validation Accuracy: 0.7178\n",
      "Epoch 10 - Accuracy: 0.9047, Validation Accuracy: 0.7281\n",
      "\n",
      "Hamming Loss: 0.089668157213462\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Testing Batch Size: 32\n",
      "Epoch 1/10\n",
      "122/122 [==============================] - 2s 12ms/step - loss: 0.3397 - accuracy: 0.5884 - val_loss: 0.2577 - val_accuracy: 0.6807\n",
      "Epoch 2/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.2293 - accuracy: 0.7509 - val_loss: 0.2220 - val_accuracy: 0.7374\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.1803 - accuracy: 0.8117 - val_loss: 0.2147 - val_accuracy: 0.7415\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.1472 - accuracy: 0.8501 - val_loss: 0.2178 - val_accuracy: 0.7446\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.1217 - accuracy: 0.8771 - val_loss: 0.2220 - val_accuracy: 0.7281\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.1021 - accuracy: 0.8954 - val_loss: 0.2328 - val_accuracy: 0.7209\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - 1s 12ms/step - loss: 0.0886 - accuracy: 0.8995 - val_loss: 0.2409 - val_accuracy: 0.7209\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - 1s 11ms/step - loss: 0.0778 - accuracy: 0.9080 - val_loss: 0.2592 - val_accuracy: 0.7106\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 0.0662 - accuracy: 0.9114 - val_loss: 0.2662 - val_accuracy: 0.7250\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - 1s 9ms/step - loss: 0.0608 - accuracy: 0.9145 - val_loss: 0.2798 - val_accuracy: 0.7178\n",
      "38/38 [==============================] - 0s 3ms/step\n",
      "Epoch 1 - Accuracy: 0.5884, Validation Accuracy: 0.6807\n",
      "Epoch 2 - Accuracy: 0.7509, Validation Accuracy: 0.7374\n",
      "Epoch 3 - Accuracy: 0.8117, Validation Accuracy: 0.7415\n",
      "Epoch 4 - Accuracy: 0.8501, Validation Accuracy: 0.7446\n",
      "Epoch 5 - Accuracy: 0.8771, Validation Accuracy: 0.7281\n",
      "Epoch 6 - Accuracy: 0.8954, Validation Accuracy: 0.7209\n",
      "Epoch 7 - Accuracy: 0.8995, Validation Accuracy: 0.7209\n",
      "Epoch 8 - Accuracy: 0.9080, Validation Accuracy: 0.7106\n",
      "Epoch 9 - Accuracy: 0.9114, Validation Accuracy: 0.7250\n",
      "Epoch 10 - Accuracy: 0.9145, Validation Accuracy: 0.7178\n",
      "\n",
      "Hamming Loss: 0.09084490468345494\n",
      "\n",
      "-----------------------------\n",
      "\n",
      "Testing Batch Size: 64\n",
      "Epoch 1/10\n",
      "61/61 [==============================] - 2s 18ms/step - loss: 0.3302 - accuracy: 0.5899 - val_loss: 0.2512 - val_accuracy: 0.7044\n",
      "Epoch 2/10\n",
      "61/61 [==============================] - 1s 15ms/step - loss: 0.2318 - accuracy: 0.7519 - val_loss: 0.2230 - val_accuracy: 0.7384\n",
      "Epoch 3/10\n",
      "61/61 [==============================] - 1s 15ms/step - loss: 0.1840 - accuracy: 0.8171 - val_loss: 0.2162 - val_accuracy: 0.7364\n",
      "Epoch 4/10\n",
      "61/61 [==============================] - 1s 15ms/step - loss: 0.1502 - accuracy: 0.8555 - val_loss: 0.2162 - val_accuracy: 0.7261\n",
      "Epoch 5/10\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 0.1230 - accuracy: 0.8779 - val_loss: 0.2200 - val_accuracy: 0.7312\n",
      "Epoch 6/10\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 0.1021 - accuracy: 0.8949 - val_loss: 0.2234 - val_accuracy: 0.7250\n",
      "Epoch 7/10\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 0.0879 - accuracy: 0.9062 - val_loss: 0.2307 - val_accuracy: 0.7312\n",
      "Epoch 8/10\n",
      "61/61 [==============================] - 1s 18ms/step - loss: 0.0759 - accuracy: 0.9132 - val_loss: 0.2378 - val_accuracy: 0.7250\n",
      "Epoch 9/10\n",
      "61/61 [==============================] - 1s 15ms/step - loss: 0.0662 - accuracy: 0.9134 - val_loss: 0.2457 - val_accuracy: 0.7230\n",
      "Epoch 10/10\n",
      "61/61 [==============================] - 1s 15ms/step - loss: 0.0576 - accuracy: 0.9256 - val_loss: 0.2556 - val_accuracy: 0.7168\n",
      "38/38 [==============================] - 0s 4ms/step\n",
      "Epoch 1 - Accuracy: 0.5899, Validation Accuracy: 0.7044\n",
      "Epoch 2 - Accuracy: 0.7519, Validation Accuracy: 0.7384\n",
      "Epoch 3 - Accuracy: 0.8171, Validation Accuracy: 0.7364\n",
      "Epoch 4 - Accuracy: 0.8555, Validation Accuracy: 0.7261\n",
      "Epoch 5 - Accuracy: 0.8779, Validation Accuracy: 0.7312\n",
      "Epoch 6 - Accuracy: 0.8949, Validation Accuracy: 0.7250\n",
      "Epoch 7 - Accuracy: 0.9062, Validation Accuracy: 0.7312\n",
      "Epoch 8 - Accuracy: 0.9132, Validation Accuracy: 0.7250\n",
      "Epoch 9 - Accuracy: 0.9134, Validation Accuracy: 0.7230\n",
      "Epoch 10 - Accuracy: 0.9256, Validation Accuracy: 0.7168\n",
      "\n",
      "Hamming Loss: 0.09202165215344787\n",
      "\n",
      "-----------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of batch sizes to test\n",
    "batch_sizes = [16, 32, 64]\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    print(f\"Testing Batch Size: {batch_size}\")\n",
    "\n",
    "    # Build model with the best learning rate, optimizer, and batch size\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation=activation_func, input_shape=(X_train_dense.shape[1],)))\n",
    "    model.add(Dropout(0.3)) \n",
    "    model.add(Dense(32, activation=activation_func))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(y.shape[1], activation='sigmoid'))\n",
    "\n",
    "    optimizer = RMSprop(learning_rate=0.001)\n",
    "\n",
    "    # Compile the model with the selected optimizer\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model with the current batch size\n",
    "    history = model.fit(X_train_dense, y_train, batch_size=batch_size, epochs=10, validation_split=0.2)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred_proba = model.predict(X_test_dense)\n",
    "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "    # Evaluate the model\n",
    "    hamming_loss_value = hamming_loss(y_test, y_pred)\n",
    "\n",
    "    # Get accuracy and validation accuracy\n",
    "    accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "    # Print the accuracy and validation accuracy for each epoch\n",
    "    for epoch in range(len(accuracy)):\n",
    "        print(f\"Epoch {epoch + 1} - Accuracy: {accuracy[epoch]:.4f}, Validation Accuracy: {val_accuracy[epoch]:.4f}\")\n",
    "\n",
    "    # Print hamming loss\n",
    "    print(\"\\nHamming Loss:\", hamming_loss_value)\n",
    "\n",
    "    print(\"\\n-----------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b513803f",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "A batch size of 16 resulted in the highest accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eb68ea",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "\n",
    "Can be considerd, computational time is not feasible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08a8d309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  5/122 [>.............................] - ETA: 2:26:37 - loss: 0.6810 - accuracy: 0.1500"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_dense\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m     18\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_dense)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/keras_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/keras_env/lib/python3.10/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/keras_env/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/keras_env/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/keras_env/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/keras_env/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/keras_env/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/keras_env/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/keras_env/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(vectorizer.vocabulary_), output_dim=128, input_length=X_train_dense.shape[1]))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(y.shape[1], activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_dense, y_train, batch_size=32, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_proba = model.predict(X_test_dense)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "hamming_loss_value = hamming_loss(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a8aa00",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "After preprocessing the following set up proved to be the best for this case.\n",
    "\n",
    "- 2 Dense Layers (64, 32) and 2 Dropout layers (0.3, 0.2)\n",
    "- Activation Function -> relu\n",
    "- Learning Rate -> 0.001\n",
    "- Optimiser -> RMSprop\n",
    "- Batch Size -> 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817c23a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
